{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75e28d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE Sessions (sid varchar(36),expires datetime,data text,createdAt datetime,updatedAt datetime, CONSTRAINT PK_Sessions PRIMARY KEY (sid))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sakir\\AppData\\Local\\Temp\\ipykernel_21472\\372570829.py:85: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql(query, cnx_mysql)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transfer for table Sessions ; 20 rows was successful in: 0 minutes 1 seconds.\n",
      "CREATE TABLE consumptions (id int,date datetime,active float,inductive float,capacitive float,hno bigint,ssno bigint,facility_id int,createdAt datetime,updatedAt datetime, CONSTRAINT PK_consumptions PRIMARY KEY (id), INDEX IX_consumptions_facility_id (facility_id))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sakir\\AppData\\Local\\Temp\\ipykernel_21472\\372570829.py:85: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql(query, cnx_mysql)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transfer for table consumptions ; 10000 rows was successful in: 0 minutes 37 seconds.\n",
      "Data transfer for table consumptions ; 10000 rows was successful in: 0 minutes 48 seconds.\n",
      "Data transfer for table consumptions ; 10000 rows was successful in: 0 minutes 37 seconds.\n",
      "Data transfer for table consumptions ; 10000 rows was successful in: 0 minutes 37 seconds.\n",
      "Data transfer for table consumptions ; 10000 rows was successful in: 0 minutes 43 seconds.\n",
      "Data transfer for table consumptions ; 10000 rows was successful in: 0 minutes 37 seconds.\n",
      "Data transfer for table consumptions ; 10000 rows was successful in: 0 minutes 40 seconds.\n",
      "Data transfer for table consumptions ; 10000 rows was successful in: 0 minutes 37 seconds.\n",
      "Data transfer for table consumptions ; 9281 rows was successful in: 0 minutes 37 seconds.\n",
      "CREATE TABLE data_by_dates (id int,facility text,district text,date datetime,active float,capacitive float,inductive float,ssno bigint,userId int,active_cons float,inductive_cons float,capacitive_cons float,createdAt datetime,updatedAt datetime, CONSTRAINT PK_data_by_dates PRIMARY KEY (id), INDEX IX_data_by_dates_userId (userId))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sakir\\AppData\\Local\\Temp\\ipykernel_21472\\372570829.py:85: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql(query, cnx_mysql)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transfer for table data_by_dates ; 666 rows was successful in: 0 minutes 8 seconds.\n",
      "CREATE TABLE data_by_hours (id int,facility text,district text,date datetime,active float,capacitive float,inductive float,ssno bigint,userId int,active_cons float,inductive_cons float,capacitive_cons float,createdAt datetime,updatedAt datetime, CONSTRAINT PK_data_by_hours PRIMARY KEY (id), INDEX IX_data_by_hours_userId (userId))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sakir\\AppData\\Local\\Temp\\ipykernel_21472\\372570829.py:85: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql(query, cnx_mysql)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transfer for table data_by_hours ; 529 rows was successful in: 0 minutes 5 seconds.\n",
      "CREATE TABLE data_by_months (id int,facility text,district text,date datetime,active float,capacitive float,inductive float,ssno bigint,userId int,active_cons float,inductive_cons float,capacitive_cons float,inductive_ratio float,capacitive_ratio float,penalized tinyint,createdAt datetime,updatedAt datetime, CONSTRAINT PK_data_by_months PRIMARY KEY (id), INDEX IX_data_by_months_userId (userId))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sakir\\AppData\\Local\\Temp\\ipykernel_21472\\372570829.py:85: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql(query, cnx_mysql)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transfer for table data_by_months ; 23 rows was successful in: 0 minutes 1 seconds.\n",
      "CREATE TABLE data_by_weeks (id int,facility text,district text,date datetime,active float,capacitive float,inductive float,ssno bigint,userId int,active_cons float,inductive_cons float,capacitive_cons float,inductive_ratio float,capacitive_ratio float,penalized tinyint,createdAt datetime,updatedAt datetime, CONSTRAINT PK_data_by_weeks PRIMARY KEY (id), INDEX IX_data_by_weeks_userId (userId))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sakir\\AppData\\Local\\Temp\\ipykernel_21472\\372570829.py:85: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql(query, cnx_mysql)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transfer for table data_by_weeks ; 275 rows was successful in: 0 minutes 4 seconds.\n",
      "CREATE TABLE firm_list (service_point_number bigint,ssno bigint,city text,district text,facility text,meter_id bigint,userId int,facility_id bigint,adress_id bigint,os_username bigint,createdAt datetime,updatedAt datetime)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sakir\\AppData\\Local\\Temp\\ipykernel_21472\\372570829.py:85: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql(query, cnx_mysql)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transfer for table firm_list ; 25 rows was successful in: 0 minutes 2 seconds.\n",
      "CREATE TABLE users (id int,uuid varchar(255),name varchar(255),email varchar(255),password varchar(255),role varchar(255),createdAt datetime,updatedAt datetime, CONSTRAINT PK_users PRIMARY KEY (id))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sakir\\AppData\\Local\\Temp\\ipykernel_21472\\372570829.py:85: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql(query, cnx_mysql)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transfer for table users ; 6 rows was successful in: 0 minutes 1 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Transfer data( include create tables, pk and fk's) from MySQL to SQL Server 08.04.2023 \n",
    "import mysql.connector\n",
    "import pyodbc\n",
    "import datetime\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "# MySQL connection env. \n",
    "db_user = <some>\n",
    "db_password = <some>\n",
    "db_host = <some>\n",
    "db_port = <some>\n",
    "db_name = <some>\n",
    "\n",
    "# Connect to MySQL database\n",
    "cnx_mysql = pymysql.connect(user=db_user, password=db_password,\n",
    "                             host=db_host, port=int(db_port), db=db_name)\n",
    "\n",
    "# Connect to SQL Server database\n",
    "cnx_sql = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "                          'SERVER=<some>;'\n",
    "                          'DATABASE=<some>;'\n",
    "                          'UID=sa;'\n",
    "                          'PWD=<some>')\n",
    "\n",
    "# Set up SQLAlchemy engine for SQL Server connection\n",
    "engine_sql = create_engine('mssql+pyodbc://sa:<some>@<some>/<some>?driver=ODBC+Driver+17+for+SQL+Server')\n",
    "# Get all table names from MySQL database\n",
    "cursor_mysql = cnx_mysql.cursor()\n",
    "cursor_mysql.execute(\"SHOW TABLES\")\n",
    "tables = cursor_mysql.fetchall()\n",
    "\n",
    "# Iterate over each table and transfer data\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "\n",
    "    # Check if table exists in SQL Server database\n",
    "    cursor_sql = cnx_sql.cursor()\n",
    "    cursor_sql.execute(f\"SELECT * FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = '{table_name}'\")\n",
    "    table_exists = len(cursor_sql.fetchall()) > 0\n",
    "    \n",
    "    if not table_exists:\n",
    "        # Fetch column names and data types from MySQL table\n",
    "        cursor_mysql.execute(f\"DESCRIBE {table_name}\")\n",
    "        columns = cursor_mysql.fetchall()\n",
    "        columns_sql = [f\"{col[0].replace('İ', 'I')} {'float' if 'double' in col[1] else col[1].replace('tinyint(1)', 'tinyint')}\" for col in columns]\n",
    "\n",
    "        cursor_mysql.execute(f\"SHOW INDEX FROM {table_name}\")\n",
    "        indexes = cursor_mysql.fetchall()\n",
    "        pk_cols = [idx[4] for idx in indexes if idx[2] == 'PRIMARY']\n",
    "        if len(pk_cols) > 0:\n",
    "            pk_constraint = f\", CONSTRAINT PK_{table_name} PRIMARY KEY ({','.join(pk_cols)})\"\n",
    "        else:\n",
    "            pk_constraint = ''\n",
    "        index_cols = [idx[4] for idx in indexes if idx[2] != 'PRIMARY']\n",
    "        if len(index_cols) > 0:\n",
    "            index_constraints = [f\"INDEX IX_{table_name}_{col} ({col})\" for col in index_cols]\n",
    "            index_constraint = f\", {','.join(index_constraints)}\"\n",
    "        else:\n",
    "            index_constraint = ''\n",
    "        \n",
    "        \n",
    "        # Generate SQL statement to create table in SQL Server\n",
    "        query = f\"CREATE TABLE {table_name} ({','.join(columns_sql)}{pk_constraint}{index_constraint})\"\n",
    "        print(query) # print the generated query\n",
    "\n",
    "        # Execute query to create table in SQL Server database\n",
    "        cursor_sql.execute(query)\n",
    "        cursor_sql.commit()\n",
    "    cursor_sql.close()\n",
    "\n",
    "    # Fetch latest timestamp from SQL Server table\n",
    "    latest_timestamp = pd.read_sql(f\"SELECT MAX(createdAt) FROM {table_name}\", engine_sql).iloc[0,0]\n",
    "    if pd.isna(latest_timestamp):\n",
    "        latest_timestamp = datetime.datetime.min\n",
    "\n",
    "    # Fetch data from MySQL table that has been updated since the last copy\n",
    "    chunk_size = 10000 # number of rows to read at a time\n",
    "    offset = 0\n",
    "    while True:\n",
    "        start_time = datetime.datetime.now()\n",
    "        query = f\"SELECT * FROM {table_name} WHERE createdAt > '{latest_timestamp}' LIMIT {chunk_size} OFFSET {offset}\"\n",
    "        data = pd.read_sql(query, cnx_mysql)\n",
    "\n",
    "        # If there is no more data to read\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "\n",
    "        # Write data to SQL Server table\n",
    "        try:\n",
    "            data.to_sql(name=table_name, con=engine_sql, if_exists='append', index=False)\n",
    "            end_time = datetime.datetime.now()\n",
    "            elapsed_time = end_time - start_time\n",
    "            elapsed_seconds = int(elapsed_time.total_seconds())\n",
    "            minutes, seconds = divmod(elapsed_seconds, 60)\n",
    "            print(f\"Data transfer for table {table_name} ; {len(data)} rows was successful in: {minutes} minutes {seconds} seconds.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Data transfer for table {table_name} failed with error: {str(e)}\")\n",
    "\n",
    "        # Increment offset for next chunk of data\n",
    "        offset += chunk_size\n",
    "\n",
    "# Close database connections\n",
    "cnx_mysql.close()\n",
    "engine_sql.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb488aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
